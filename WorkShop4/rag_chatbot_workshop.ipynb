{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad849b5a",
   "metadata": {},
   "source": [
    "# Workshop 4: RAG Chatbot with FAISS, LangChain, and Azure OpenAI Function Calling\n",
    "\n",
    "This notebook walks through building a Retrieval-Augmented Generation (RAG) chatbot using:\n",
    "- FAISS for vector search\n",
    "- LangChain for retrieval and conversation orchestration\n",
    "- Azure OpenAI (Chat + Embeddings) with function/tool calling to extend capabilities\n",
    "\n",
    "You'll be able to: generate embeddings, build a FAISS index over mock data, retrieve relevant context, chat with the model, and invoke functions like checking device status or creating an IT ticket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b5509",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Python 3.9+\n",
    "- Install dependencies (if running locally):\n",
    "  - langchain, langchain-openai, langchain-community, faiss-cpu, openai, tiktoken, python-dotenv, jupyter, ipykernel\n",
    "- Azure OpenAI resource with a Chat model (e.g., gpt-4o-mini) and an Embeddings model (e.g., text-embedding-3-large) deployed.\n",
    "\n",
    "Environment variables (use a .env file or set in your shell):\n",
    "- AZURE_OPENAI_API_KEY=...\n",
    "- AZURE_OPENAI_ENDPOINT=https://<your-azure-openai>.openai.azure.com/\n",
    "- AZURE_OPENAI_API_VERSION=2024-07-01-preview\n",
    "- AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini (your chat deployment name)\n",
    "- AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT=text-embedding-3-large (your embeddings deployment name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e78176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup & imports\n",
    "import os, json, textwrap\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# LangChain & Vector store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# OpenAI SDK (Azure) for tool/function calling\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Utility\n",
    "def require_env(names: List[str]):\n",
    "    missing = [n for n in names if not os.getenv(n)]\n",
    "    if missing:\n",
    "        print(\"[WARN] Missing env vars ->\", missing)\n",
    "    else:\n",
    "        print(\"[OK] Environment variables detected.\")\n",
    "\n",
    "require_env([\n",
    "    'AZURE_OPENAI_API_KEY',\n",
    "    'AZURE_OPENAI_ENDPOINT',\n",
    "    'AZURE_OPENAI_API_VERSION',\n",
    "    'AZURE_OPENAI_CHAT_DEPLOYMENT',\n",
    "    'AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116fb197",
   "metadata": {},
   "source": [
    "## Mock data: IT Helpdesk FAQ\n",
    "You can swap this with your team's domain (e.g., HR, Sales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eefaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_docs = [\n",
    "    {\n",
    "        'page_content': 'How to reset my password? Visit the password reset page and follow the emailed instructions.',\n",
    "        'metadata': {'source': 'FAQ - Password Reset'}\n",
    "    },\n",
    "    {\n",
    "        'page_content': 'My computer is slow. Restart it, close unused apps, and run antivirus scans.',\n",
    "        'metadata': {'source': 'FAQ - Performance Issues'}\n",
    "    },\n",
    "    {\n",
    "        'page_content': 'To connect to VPN, install the client from IT portal and login with your credentials.',\n",
    "        'metadata': {'source': 'FAQ - VPN Setup'}\n",
    "    },\n",
    "    {\n",
    "        'page_content': 'Printer not working? Ensure itâ€™s powered on, connected, and has ink and paper.',\n",
    "        'metadata': {'source': 'FAQ - Printer Troubleshooting'}\n",
    "    },\n",
    "]\n",
    "len(mock_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c797ff8",
   "metadata": {},
   "source": [
    "## Build embeddings and FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a07a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Azure OpenAI clients\n",
    "AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "AZURE_OPENAI_API_VERSION = os.getenv('AZURE_OPENAI_API_VERSION', '2024-07-01-preview')\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT = os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT')\n",
    "AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT = os.getenv('AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT')\n",
    "\n",
    "# Embeddings for FAISS\n",
    "emb_kwargs = dict(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    ")\n",
    "if AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT:\n",
    "    emb_kwargs['azure_deployment'] = AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(**emb_kwargs)\n",
    "\n",
    "texts = [d['page_content'] for d in mock_docs]\n",
    "metas = [d['metadata'] for d in mock_docs]\n",
    "vectorstore = FAISS.from_texts(texts, embedding=embeddings, metadatas=metas)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 3})\n",
    "\n",
    "print('FAISS index built. Vector count:', vectorstore.index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46c689",
   "metadata": {},
   "source": [
    "## Set up Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_deployment=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "retrieval_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=chat,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# History as a list of (user, assistant) tuples\n",
    "chat_history: List[Tuple[str, str]] = []\n",
    "print('ConversationalRetrievalChain ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971a3ec",
   "metadata": {},
   "source": [
    "## Define functions (tools) for Azure OpenAI to call\n",
    "We'll implement two example tools: check_system_status and create_it_ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock functions\n",
    "def check_system_status(device_id: str) -> str:\n",
    "    status_map = {\n",
    "        'printer01': 'Online and functioning normally.',\n",
    "        'router23': 'Offline - requires restart.',\n",
    "        'server07': 'Online but high CPU usage.',\n",
    "    }\n",
    "    return status_map.get(device_id, 'Device not found.')\n",
    "\n",
    "def create_it_ticket(issue: str, urgency: str = 'medium') -> str:\n",
    "    import random\n",
    "    ticket_id = f'TKT-{random.randint(1000,9999)}'\n",
    "    return f'Ticket {ticket_id} created for issue: \n",
    " (urgency={urgency}).'\n",
    "\n",
    "# Tool schema for Azure OpenAI (Chat Completions)\n",
    "tools_schema = [\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'check_system_status',\n",
    "            'description': 'Checks device status by device ID',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'device_id': {'type': 'string', 'description': 'Device unique identifier'}\n",
    "                },\n",
    "                'required': ['device_id']\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'create_it_ticket',\n",
    "            'description': 'Creates an IT support ticket for a described issue',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'issue': {'type': 'string', 'description': 'Users issue description'},\n",
    "                    'urgency': {'type': 'string', 'enum': ['low','medium','high']}\n",
    "                },\n",
    "                'required': ['issue']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Azure OpenAI client\n",
    "aoai_client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    'You are an IT helpdesk assistant. Use the provided knowledge and call tools when helpful. '\n",
    ")\n",
    "\n",
    "def call_tools_if_requested(message: Dict[str, Any]) -> List[Dict[str, str]]:\n",
    "    \"\"\"Handle tool calls by executing local Python functions and returning tool outputs as messages.\n",
    "    Returns a list of new messages (assistant tool calls + tool outputs) to append.\n",
    "    \"\"\"\n",
    "    followups = []\n",
    "    tool_calls = message.get('tool_calls') or []\n",
    "    for tool_call in tool_calls:\n",
    "        func = tool_call['function']['name']\n",
    "        args_json = tool_call['function'].get('arguments') or '{}'\n",
    "        try:\n",
    "            args = json.loads(args_json) if isinstance(args_json, str) else args_json\n",
    "        except Exception:\n",
    "            args = {}\n",
    "        # Execute corresponding function\n",
    "        if func == 'check_system_status':\n",
    "            out = check_system_status(**args)\n",
    "        elif func == 'create_it_ticket':\n",
    "            out = create_it_ticket(**args)\n",
    "        else:\n",
    "            out = f'Unknown tool: {func}'\n",
    "        # Represent the tool result as a tool message\n",
    "        followups.append({\n",
    "            'role': 'tool',\n",
    "            'tool_call_id': tool_call.get('id', ''),\n",
    "            'name': func,\n",
    "            'content': out,\n",
    "        })\n",
    "    return followups\n",
    "\n",
    "def chat_with_rag_and_tools(query: str, chat_history: List[Tuple[str, str]]):\n",
    "    # 1) Retrieve knowledge via LangChain\n",
    "    rag = retrieval_chain({'question': query, 'chat_history': chat_history})\n",
    "    sources = rag.get('source_documents', [])\n",
    "    knowledge = '\n",
    "\n",
    "'.join([f\"- {d.metadata.get('source')}: {d.page_content}\" for d in sources])\n",
    "\n",
    "    # 2) Build messages for Azure OpenAI tools\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "        {'role': 'system', 'content': f'Relevant knowledge:\n",
    "{knowledge}' if knowledge else 'No knowledge retrieved.'}\n",
    "    ]\n",
    "    for q, a in chat_history:\n",
    "        messages.append({'role': 'user', 'content': q})\n",
    "        messages.append({'role': 'assistant', 'content': a})\n",
    "    messages.append({'role': 'user', 'content': query})\n",
    "\n",
    "    # 3) First model call (may request tools)\n",
    "    first = aoai_client.chat.completions.create(\n",
    "        model=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
    "        messages=messages,\n",
    "        tools=tools_schema,\n",
    "        tool_choice='auto'\n",
    "    )\n",
    "    msg = first.choices[0].message\n",
    "\n",
    "    # 4) If tools requested, execute and send follow-up\n",
    "    if getattr(msg, 'tool_calls', None):\n",
    "        # Append assistant tool-calling message\n",
    "        messages.append({'role': 'assistant', 'content': msg.content or '', 'tool_calls': [tc.model_dump() for tc in msg.tool_calls]})\n",
    "        # Call local tools\n",
    "        for tc in msg.tool_calls:\n",
    "            func = tc.function.name\n",
    "            args = tc.function.arguments\n",
    "            try:\n",
    "                parsed = json.loads(args) if isinstance(args, str) else args\n",
    "            except Exception:\n",
    "                parsed = {}\n",
    "            if func == 'check_system_status':\n",
    "                out = check_system_status(**parsed)\n",
    "            elif func == 'create_it_ticket':\n",
    "                out = create_it_ticket(**parsed)\n",
    "            else:\n",
    "                out = f'Unknown tool: {func}'\n",
    "            messages.append({\n",
    "                'role': 'tool',\n",
    "                'tool_call_id': tc.id,\n",
    "                'name': func,\n",
    "                'content': out,\n",
    "            })\n",
    "        # 5) Second model call to get final answer\n",
    "        second = aoai_client.chat.completions.create(\n",
    "            model=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
    "            messages=messages\n",
    "        )\n",
    "        final_msg = second.choices[0].message\n",
    "        answer = final_msg.content\n",
    "    else:\n",
    "        answer = msg.content\n",
    "\n",
    "    chat_history.append((query, answer))\n",
    "    return {\n",
    "        'answer': answer,\n",
    "        'sources': [\n",
    "            {'source': d.metadata.get('source'), 'content': d.page_content} for d in sources\n",
    "        ]\n",
    "    }\n",
    "\n",
    "print('Tools and Azure OpenAI client configured.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31313245",
   "metadata": {},
   "source": [
    "## Try it: single query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df74a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Printer not working. What should I do? Also check printer01 status.'\n",
    "result = chat_with_rag_and_tools(query, chat_history)\n",
    "print('Answer:\n",
    "', textwrap.fill(result['answer'], 100))\n",
    "print('\n",
    "Sources:')\n",
    "for s in result['sources']:\n",
    "    print('-', s['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0295a489",
   "metadata": {},
   "source": [
    "## Multi-turn demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "turns = [\n",
    "    'How do I reset my password?',\n",
    "    'My computer is slow, what should I try?',\n",
    "    'Create a ticket for slow performance with high urgency.',\n",
    "]\n",
    "for t in turns:\n",
    "    r = chat_with_rag_and_tools(t, chat_history)\n",
    "    print('\n",
    "User:', t)\n",
    "    print('Assistant:', textwrap.fill(r['answer'], 100))\n",
    "print('\n",
    "Done. Conversation length:', len(chat_history))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
